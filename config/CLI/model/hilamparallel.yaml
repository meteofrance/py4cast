model:
  model_name: HiLAMParallel
  model_conf: null # Path to model_conf
  loss_name: mse # mse or mae
  num_inter_steps: 1 # Number of intermediary steps (without any data)
  num_samples_to_plot: 1
  training_strategy: diff_ar # diff_ar or scaled_ar
  channels_last: False # True: B W H C
  io_conf : null
  mask_ratio : 0 # 0<mask_ratio<1. If !=0 apply maskedautoencoderstrategy. 
  settings_init_args:
    tmp_dir: /tmp  # nosec B108
    hidden_dims: 64
    hidden_layers: 1
    use_checkpointing: False
    offload_to_cpu: False
    mesh_aggr: sum
    processor_layers: 4